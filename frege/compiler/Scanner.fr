// enable UTF-8: «««««»»»»»»
/**
 * This is the scanner for the frege compiler.
 *
 * Essentialy, there are the following important functions:
 * - the 'scan' function turns a list of strings into a list of 'Token's.
 * - the 'layout' function takes the output from 'scan' and inserts
 *   braces and semicolons according to layout rules.
 * - the 'substAllOp' functions scans the output of the scan function and
 *   replaces sequences of single characters with operator symbols according
 *   to a table.
 *
 * The 'scan' function has no way to know what operators are defined in the
 * current source file or in imported packages. In previous versions of the
 * compiler, this has been solved by calling import and updating the operator tree
 * via a reference as soon as the parser reduced an "import" or "infix" declaration.
 * Nowadays, we
 * 0. build an initial operator table from the Prelude
 * 1. scan without knowledge of the operators,
 * 2. do the layout,
 * 3. look for fixity definitions and imports
 * 4. complete the operator table
 *    (which causes 'IO' actions in case of imports)
 * 5. substitute characters with operators
 *
 * The resulting token list is ready to be passed to the parser.
 * This way, parser and scanner are decoupled and are pure functions,
 * with the exception of the part that builds the operator table.
 *
 */


/*
 * $Author: ingo $
 * $Revision: 241 $
 * $Date: 2011-03-01 19:31:05 +0100 (Di, 01 Mrz 2011) $
 * $Id: Scanner.fr 241 2011-03-01 18:31:05Z ingo $
 */
package frege.compiler.Scanner where

/// This is $Revision: 241 $
public version = v "$Revision: 241 $" where
    v (m ~ #(\d+)#) | Just g <- m.group 1 = g.atoi
    v _ = 0


// import of library packages

import frege.IO(`<<` stdout stderr stdin
                BufferedReader FileInputStream InputStream InputStreamReader)
import frege.List(joinStr Tree keys contains fromKeys each)

// import of compiler packages
import frege.compiler.Data
import frege.compiler.Classtools (mkClassLoader getOperators Operator OpArr)
import frege.compiler.Utilities  (cval) as U


/**
 * A map of keywords to 'TokenID's
 */
kwtree = Tree.insertlist Nil [
    ("package", PACKAGE),
    ("import" ,  IMPORT),
    ("native" ,  NATIVE),
    ("if" ,  IF),
    ("then" ,  THEN),
    ("else" ,  ELSE),
    ("class" ,  CLASS),
    ("interface" ,  CLASS),
    ("where" ,  WHERE),
    ("instance" ,  INSTANCE),
    ("of" ,  OF),
    ("derive" ,  DERIVE),
    ("data" ,  DATA),
    ("extends" ,  EXTENDS),
    ("case" ,  CASE),
    ("let" ,  LET),
    ("in" ,  IN),
    ("type" ,  TYPE),
    ("true" ,  TRUE),
    ("false" ,  FALSE),
    ("protected" ,  PROTECTED),
    ("private" ,  PRIVATE),
    ("public" ,  PUBLIC),
    ("pure",     PURE),
    ("abstract", ABSTRACT),
    ("do" ,  DO),
    ("forall" ,  FORALL),
    ("continue" ,  CONTINUE),
    ("break" ,  BREAK),
    ("while" ,  WHILE),
    ("infix" ,  INFIX),
    ("infixl" ,  INFIXL),
    ("infixr" ,  INFIXR)];


//* standard operators, this are the multi character special symbols
standardops = [
        ("::", DCOLON), ("->", ARROW), ("<-", GETS),
        ("_", CHAR), ("\\", CHAR), (".", CHAR), (";", CHAR), (",", CHAR),
        ("!", CHAR), ("?", CHAR),  ("|", CHAR), ("=", CHAR),
        ("$", CHAR), ("+", CHAR),  ("-", CHAR), (":", CHAR),
        ("<", CHAR), (">", CHAR),  ("~", CHAR), ("%", CHAR),
        ("&", CHAR), ("*", CHAR),  ("/", CHAR), ("@", CHAR),
        ("(", CHAR), (")", CHAR),  ("[", CHAR), ("]", CHAR),
        ("{", CHAR), ("}", CHAR),
        ("°", CHAR), // backward compatibility
    ];

standardtops = Tree.fromList standardops

/**
 * checks if a user defined operator obeys certain rules:
 * - it must not be one of "=" "|" "," ";" "." "\\" "_"
 * - it must not contain braces, square brackets or parentheses
 * - it must not conatin one of the quoting characters " \' ` or #
 * - it must not conatin digits
 * - it must consist of either all word characters or all non word characters
 */
validop "=" = false;
validop "|" = false;
validop "?" = false;
validop "!" = false;
validop "," = false;
validop ";" = false;
validop "." = false;
validop "\\" = false;
validop "_" = false;
validop "::" = false;
validop "<-" = false;
validop "->" = false;
validop #[\(\[\{\}\]\)]# = false;
validop #["`'\#]# = false;
validop #\d# = false;
validop #^\w+$# = true;
validop #^\W+$# = true;
validop _ = false;

/**
 * tells if character is forbidden in operator
 */
// forbidden ','  = true
// forbidden '.'  = true
// forbidden ';'  = true
forbidden '#'  = true
forbidden '"'  = true
forbidden '\'' = true
forbidden '`'  = true
forbidden '('  = true
forbidden ')'  = true
forbidden '['  = true
forbidden ']'  = true
forbidden '{'  = true
forbidden '}'  = true
// forbidden c    = c.isWhitespace || c.isLowerCase || c.isUpperCase || c >= '0' && c <= '9'
// forbidden c | c >= '0', c <= '9' = true
forbidden _    = false



/**
 * makes a 'Regex' that matches any string in /ops/
 */
opat ops = orops.compile where
    qops  =  (map String.quote <~ sortBy (descending String.length)) ops
    orops = "\\G(" ++ joinStr "|" qops ++ ")"


opp = opat (map fst standardops)

/**
 * tells if the argument is a real operator,
 * i.e. one that consists of non word characters only
 */
realop #^\W+$# = true
realop _       = false

/// look up a standardop
getop s = standardtops.lookup s;


// tokenizeXXX ls = layout (scan 1 ls) [0];


/// check whether 'Token' is a specific char
is :: Token -> Char -> Bool
is t c = t.tokid == CHAR && t.value.charAt 0 == c

/// check whether 'Token' is not a specific char
isNot :: Token -> Char -> Bool
isNot t c = t.tokid != CHAR || t.value.charAt 0 != c



/**
    This function does the layout on a list of
    'Token's. The result is another list
    of 'Token's with some extra semicolons
    and braces in the correct places.

    The first argument is the context represented by a list of integers,
    where each element is either:
    - Zero, indicating that the enclosing context is explicit
     (i.e. the programmer supplied the opening brace).
     If the innermost context is 0, then no layout tokens will be inserted until
     either the enclosing context ends or a new context is pushed.
    - A positive integer, which is the indentation column of the enclosing layout context.

    The indentation of a token is the column number indicating the start of that token;
    the indentation of a line is the indentation of its leftmost lexeme.
    To determine the column number, assume a fixed-width font. For the purposes
    of the layout rule, Unicode characters in a source
    program are considered to be of the same, fixed, width as an ASCII character.
    The first column is designated column 1, not 0.

    The layout is done according to the following rules:

*/
layout :: [Int] -> [Token] -> [Token]

///  1) an explicit \'{\' starts a new explicit context
layout !ctx (t1:ts)
    | t1 `is` '{' = t1 : layout (0:ctx) ts

///  2) an explicit \'}\' can only occur in explicit context and closes this context
layout (0:ms) (t1:ts)
    | t1 `is` '}', t1.col > 0  = layout ms (Token CHAR "}2" t1.line 0:ts)

/**
    3) if a *@let@*, *@do@*, *@where@* or *@of@* is not followed by \'{\'
       and the position of the next token is greater than the
       current context, insert \'{\' and push that position as new context.

    4) If the position of the first token on a line matches the context,
       a \';\' is inserted before that token, except when the last token
       on the last line was already a semicolon.

    5) If the position of the first token on a line is less than the context,
       the context is closed and a closing brace is inserted.

    6) If *@in@* is found in layout mode
       without preceding closing brace, the closing brace is inserted
       and the context is closed

    7) At the end of the program, if there are open layout contexts,
       a corresponding number of closing braces is inserted.
*/
layout (m:ms) (t1:t2:ts)
    | kw t1.tokid, t2 `isNot` '{', t2.col > m
    = t1 : Token CHAR "{3" t1.line 0 : layout (t2.col:m:ms) (t2:ts)
    | t2.line > t1.line, t2.col == m, t1 `isNot` ';'
    = t1 : Token CHAR ";4" t1.line 0 : layout (m:ms) (t2:ts)
    | t2.line > t1.line, t2.col < m
    = t1 : layout ms (Token CHAR "}5" t1.line 0 : t2 : ts)
    | m != 0, t2.tokid == IN, t1 `isNot` '}'
    = t1 : Token CHAR "}6" t1.line 0 : layout ms (t2:ts)
    where
        kw LET = true; kw DO  = true; kw WHERE = true; kw OF = true; kw _ = false

layout ms (t1:ts) = t1:layout ms ts
layout [0] []     = []              // proper end.
layout (m:ms) []
    | m > 0 = Token CHAR "}7" Int.maxBound Int.maxBound : layout ms []
    | otherwise = layout ms []    // explicit brace missing

layout ms ts =
    traceLn ("layout " ++ show ms ++ "   " ++ show (take 3 ts)) `seq` []


/**
 * Scans the string in the input list and returns a list of 'Token's.
 * For each scanned token, there is one item giving
 * - the token identifier that was recognized
 * - the string that was matched
 * - the line number where the string occured
 * - the 1-based start position (column) of the token.
 *
 * The real work is done in various scan.... functions of type
 * > Line -> Matcher -> [String] -> [Token]
 * where the following invariants are maintained:
 *
 * 1) the 'Matcher' has just performed a successful match
 *
 * 2) the 'String' list is not empty
 *
 * 3) the 'head' of the 'String's is the one the 'Matcher' operates on
 */
scan !n [] = [];
scan !n (lns@ln:ls) = case (##.matcher ln).find of
        Just mgc ->  scanSelect n mgc lns
        Nothing  ->  error ("Can't match ## in '" ++ ln ++ "'")  // then we have REAL problems ...


/**
    This function selects the next scan function based on the next character.

    Earlier design tried one pattern after the other, but with the now immutable
    'Matcher', this involves cloning of the matcher for each try. Which is,
    as some profiling exposed, the single most expensive operation. The new approach
    will need at most two tries.

    If the first character is
    [\/] we use 'scanCommentStart' (1 find operation)
    [a lowercase letter] we use 'scanId' (1 find operation)
    [an uppercase letter] we use 'scanQ' (1 find operation)
    [a space character] we just skip and tailrecurse (1 find operation)
    [a digit 0..9] we use 'scanNumber' (2 find operations)
    ["] we use 'scanString' (1 find operation)
    [#] we use 'scanRegexp' (1 find operation)
    [\'] we use 'scanChar' (1 find operation)
    [anything else] we use 'scanSpecial' (1 find operation)
*/
scanSelect :: Line -> Matcher -> [String] -> [Token]
scanSelect !n mgc (currls@ln:lns)
    // | trace ("line=" ++ show n ++ ", offset=" ++ show offset ++ ", matcher=" ++ mgc.toString ++ "\n") = undefined
    | endOfLine = scan (n+1) lns                   // end of line was reached
    | c == '/'       = scanCommentStart n mgc currls
    | c.isLowerCase  = scanId n mgc currls
    | c.isUpperCase  = scanQ  n mgc currls
    | c.isWhitespace = scanSelect n (unJust (mgc ?~ #\G\p{javaWhitespace}+#)) currls // skip
    | c >= '0' && c <= '9' = scanNumber n mgc currls
    | c == '"'       = scanString  n mgc currls
    | c == '#'       = scanRegexp  n mgc currls
    | c == '\''      = scanChar    n mgc currls
    | c == '`'       = scanOp      n mgc currls
    | otherwise      = scanSpecial n mgc currls
    where
        offset    = mgc.end 0
        endOfLine = offset >= ln.length
        !c        = if endOfLine then '\n' else String.charAt ln offset
scanSelect !n mgc [] = error ("scanSelect " ++ show n ++ "  " ++ mgc.toString ++ " []")


//* matches \'/\' or start of a comment
commentStart = #\G/(/{1,2}|\*{1,2})?#
/**
    When the 'Matcher' points to a \'\/\' this can be the start of a block or line
    comment, where both may also be doc-comments.
    Otherwise it is just the character \'\/\'
*/
scanCommentStart n mgc lns = case mgc ?~ commentStart of
    Just mgc -> let
            offset = mgc.start 0
            value  = unJust (mgc.group 0)
            rest   = strtail (head lns) (mgc.end 0)
        in case unJust (mgc.group 0) of
            "/**" -> scancomment 1 n (offset + 1) n mgc lns true  ""
            "/*"  -> scancomment 1 n (offset + 1) n mgc lns false ""
            "///" -> let
                         !tok = Token DOCUMENTATION (rest ++ "\n\n") n (offset + 1)
                     in tok : scan (n+1) (tail lns)
            "//"  -> scan (n+1) (tail lns)
            "/"   -> let
                        !tok = Token CHAR ("/") n (offset + 1)
                     in tok : scanSelect n mgc lns
            wrong -> error ("somebody changed commentStart, matched '" ++ wrong ++ "'")
    Nothing -> error (show n ++ " scanCommentStart: " ++ strtail (head lns) (mgc.end 0))

//* special operators or just character
special = #\G->|<-|::|.#

/**
 * match single character operators
 */
scanSpecial n mgc lns =
    case mgc ?~ #\G.# of
        Just mgc  -> let
                s = unJust (mgc.group 0)
                ind = 1 + mgc.start 0
                f = /* case s of
                    "->"  -> ARROW
                    "<-"  -> GETS
                    "::"  -> DCOLON
                    _     -> */ CHAR
                !tok = Token f s n ind
            in tok : scanSelect n mgc lns
        Nothing -> error (show n ++ " scanSpecial: "
                        ++ strtail (head lns) (mgc.end 0))


/**
 * matches Ident[.Ident].
 */
qualifier = #\G(?:\p{Lu}(?:\d|_|\p{L})*\.){1,2}#;

/**
 * matches Ident
 */
iDent = #\G\p{Lu}(?:\d|_|\p{L})*#;

/**
 * Matches qualifier or constructor name.
 * The pattern is @Ident(.(Ident.)?)?@
 * If it matches and group 1 is present, then it's a qualifier
 * else it's a constructor
 */
qualID = #\G\p{Lu}(?:\d|_|\p{L})*(\.(?:\p{Lu}(?:\d|_|\p{L})*\.)?)?#

/**
 * Match qualifier or constructor name using 'qualID'. The 'Matcher' must
 * point to an uppercase letter.
 */
scanQ  n mgc lns =
    case mgc ?~ qualID of {
        Just mgc -> let
                q = unJust (mgc.group 0)  // the qualifier or Ident
                qstart = 1 + mgc.start 0  // and its position
                f = if isJust (mgc.group 1) then QUALIFIER else CONID
                !tok = Token f q n qstart
            in  tok : scanSelect n mgc lns;
        Nothing -> error (show n ++ " scanQ: " ++ strtail (head lns) (mgc.end 0))
    }

/**
 * matches identifier
 */
ident = #\G\p{Ll}(?:\d|_|\p{L})*'*#;


/**
 * Match identifier or keyword using 'ident'.
 *
 * Precondition: the matcher points to a lowercase letter so that the pattern
 * always matches.
 */
scanId n mgc lns =
    case mgc ?~ ident of
        Just mgc  ->
            let
                s   = unJust (mgc.group 0)
                ids = 1 + mgc.start 0
                f = case Tree.lookup kwtree s of
                    Just f  -> f // (f, s, n, ids)    : scanSelect n mgc lns
                    Nothing -> VARID
                !tok = Token f s n ids
            in tok : scanSelect n mgc lns
        Nothing -> error (show n ++ " scanId: " ++ strtail (head lns) (mgc.end 0))

//* a hexadecimal number
hexlit = #\G0([xX][0-9a-fA-F]+)([lL])?#;
//* a decimal number
fltlit = #\G(\d+(?:_\d\d\d)*)(\.\d+)?([eE][+-]?\d+)?([fFdDlLnN])?#;

/**
 * Find a numeric literal.
 *
 * The matcher must point to a digit.
 */
scanNumber n mgc lns =
    case mgc ?~ hexlit of {
        Just mgc -> let
                lit = unJust (mgc.group 0)
                ind = 1 + mgc.start 0
                f = case mgc.group 2 of
                    Nothing -> INTCONST // (INTCONST,  lit, n, ind) : scanSelect n mgc lns;
                    Just _  -> LONGCONST // (LONGCONST, lit, n, ind) : scanSelect n mgc lns;
                    Just _  -> LONGCONST // (LONGCONST, lit, n, ind) : scanSelect n mgc lns;
                !tok = Token f lit n ind
            in tok : scanSelect n mgc lns
        ;
        Nothing -> case mgc ?~ fltlit of {
            Nothing -> error (show n ++ " scanNumber: " ++ strtail (head lns) (mgc.end 0));
            Just mgc -> let
                         fx = unJust (mgc.group 0)
                         ind = 1 + mgc.start 0
                         dx = unJust (mgc.group 1)
                         f = (#_#.matcher fx).replaceAll ""
                         d = (#_#.matcher dx).replaceAll ""
                         !tok = case (mgc.group 2, mgc.group 3, mgc.group 4) of {
                (Nothing, Nothing, Nothing)     -> Token INTCONST  f n ind;
                (Nothing, Nothing, Just "l")    -> Token LONGCONST f n ind;
                (Nothing, Nothing, Just "L")    -> Token LONGCONST f n ind;
                (Nothing, Nothing, Just "N")    -> Token BIGCONST  d n ind;
                (Nothing, Nothing, Just "n")    -> Token BIGCONST  d n ind;
                (_, _, Just "d")                -> Token DBLCONST  f n ind;
                (_, _, Just "D")                -> Token DBLCONST  f n ind;
                (_, _, Just "f")                -> Token FLTCONST  f n ind;
                (_, _, Just "F")                -> Token FLTCONST  f n ind;
                (Just _, _, Nothing)            -> Token DBLCONST  f n ind;
                (_, Just _, Nothing)            -> Token DBLCONST  f n ind;
                bad                             -> error ("bad number " ++ fx ++ " " ++ show bad); }
                    in tok : scanSelect n mgc lns;
        }
    };

//* matches a string literal
strlit = #\G"(\\[0-7][0-7]|\\[0-7]|\\[0123][0-7][0-7]|\\.|[^"])*"#;

/**
 * find a string literal

 * The matcher must point to a \'"\'
 */
scanString n mgc lns = case mgc ?~ strlit of
        Just mgc  -> let
                !tok = Token STRCONST (unJust (mgc.group 0)) n (1 + mgc.start 0)
            in tok : scanSelect n mgc lns
        Nothing -> scanSpecial n mgc lns   // error (show n ++ " scanString: " ++ strtail (head lns) (mgc.end 0))

//* matches a char literal
chrlit = #\G'(\\[0-7][0-7]|\\[0-7]|\\[0123][0-7][0-7]|\\.|[^'\\])'#;

/**
 * Find a character literal.

 * The matcher must point to a \'\\\'\'
 */
scanChar n mgc lns =
    case mgc ?~ chrlit of
        Just mgc -> let
                    !tok = Token CHRCONST (unJust (mgc.group 0)) n (1 + mgc.start 0)
                in tok : scanSelect n mgc lns
        Nothing -> scanSpecial n mgc lns    // error (show n ++ " scanChar: " ++ strtail (head lns) (mgc.end 0))

//* matches a regular expression
regexp = #\G\#((\\#|[^\#])*)\##
/**
 * Find a regexp literal.

 * The matcher must point to a \'#\'
 */
scanRegexp n mgc lns =
    case mgc ?~ regexp of
        Just mgc  -> let
                r = unJust (mgc.group 0)
                ind = 1 + mgc.start 0
                rex = fromMaybe "" (mgc.group 1)
                !tok = Token REGEXP rex n ind
            in tok : scanSelect n mgc lns
        Nothing -> scanSpecial n mgc lns   // error (show n ++ " scanRegexp: " ++ strtail (head lns) (mgc.end 0))


//* an operator in backticks, either all word or all non word chars
idop  = #\G`(\w+|[^"'`\#{}\[\]()\w]+)`#

/**
 * Find an operator in backticks
 *
 * The matcher must point to a backtick.
 */
scanOp n mgc lns =
        case mgc ?~ idop of
            Just mgc -> let
                    // s = unJust (mgc.group 0)
                    ind = 1+ mgc.start 0
                    o = fromMaybe "" (mgc.group 1)
                    !tok= Token SOMEOP o n ind
                in tok : scanSelect n mgc lns
            Nothing -> scanSpecial n mgc lns   // error (show n ++ " scanOp: " ++ strtail (head lns) (mgc.end 0))

/**
 * scan a block comment and recognize enclosed comment blocks, thereby collecting
 * the comment text in case it is a doc comment.
 */
scancomment lvl sln spos n mgc lns doc acc
    /*| trace ("scancomment n=" ++ show n ++ ", doc=" ++ show doc ++ ", matcher=" ++ Matcher.toString mgc ++ "\n") = undefined
    | otherwise */ =  case mgc ?~ #\G\*/# of {
        Just mgc  -> if lvl == 1
                then if doc
                    then let
                          !tok = Token DOCUMENTATION (acc ++ "\n\n") sln spos
                        in tok : scanSelect n mgc lns
                    else scanSelect n mgc lns
                else scancomment (lvl-1) sln spos n mgc lns doc (acc ++ "*/");
        Nothing -> case mgc ?~ #\G/\*# of {
            Just mgc -> scancomment (lvl+1) sln spos n mgc lns doc (acc ++ unJust (mgc.group 0));
            Nothing -> case mgc ?~ #\G$# of {
                Just _  -> case tail lns of {
                    []   -> error ("end of input while in comment started in line " ++ show sln);
                    tls -> let
                                nmgc = unJust (##.matcher (head tls)).find
                            in scancomment lvl sln spos (n+1) nmgc tls doc (acc ++ "\n");
                };
                Nothing -> case mgc ?~ #\G.[^*/]*# of {
                    Just mgc  -> scancomment lvl sln spos n mgc lns doc (acc ++ unJust (mgc.group 0));
                    Nothing -> error ("Can't match any char in comment line " ++ show n);
                };
            };
        };
    } where {
        unstar (m~#^(\s+\*+\s+)(.*)$#) | Just s <- m.group 2 = s;
        unstar s = s;
    };


/**
 * Find @infix@ and @import@ declarations in token stream.
 */
findInfixImports :: [Token] -> [[Token]]
findInfixImports ts = loop start ts where
    start = [[Token IMPORT "import" 0 0, Token VARID "frege.Prelude" 0 0]] // import frege.Prelude
    loop acc [] = acc
    loop acc (t1:ts)
        | wanted (Token.tokid t1) = loop ((t1:this ts) : acc) (tail ts)
        | otherwise = loop acc ts
        where
            isImport = Token.tokid t1 == IMPORT
            wanted IMPORT = true
            wanted INFIXL = true
            wanted INFIXR = true
            wanted INFIX  = true
            wanted _      = false
            // no separators
            consecutive :: [Token] -> [Token]
            consecutive (t1:(ts@t2:_))
                | t1.line != t2.line                 = [t1]
                | t1.col + t1.value.length != t2.col = [t1]
                | otherwise                          = t1:consecutive ts
            consecutive rest                         = rest
            separator t = t `is` '}' || t `is` ';'
            this ts = if isImport then consecutive (takeUntil separator ts) else takeUntil separator ts
            // next ts = drop (length this) ts
            // this ts = t1 : takeUntil separator ts
            // next ts = case dropUntil separator ts of
            //    [] -> []
            //    xs -> tail xs

/// special symbols in tree
specialT = Tree.fromList [("::", DCOLON), ("=>", EARROW), ("~>", TARROW),
                            ("->", ARROW), ("<-", GETS)]

/**
 * build a map from 'String's to 'TokenID's, which serves as dictionary of operators
 */
// processInfixImport :: [Token] ->(String ->  Either (Line, String) (Tree String TokenID)
processImports prefix getop (err@Left _) xs = IO.return err
processImports prefix getop (tree@Right _) [] = IO.return tree
processImports prefix getop (tree@Right _) (cmd:cmds)
        | (t1:ts) <- cmd, Token.tokid t1 == IMPORT = do
            imp <- mkImport t1.line ts tree
            processImports prefix getop imp cmds
        | otherwise = processImports prefix getop tree cmds
        where
    mkImport _ _  (err@Left _)    = IO.return err
    mkImport n ts (tree@Right _)
        | null name = IO.return $ Left (n, "Package name missing after «import»")
        | otherwise = do
            (loaded::Exception (Maybe OpArr)) <- getop name
            case loaded of
                // we can ignore non existance of frege.Prelude for now,
                // because either we are compiling frege.Prelude itself, when it can't be
                // there already, or we are compiling something else and then we will
                // see the error in the import pass, because every package except frege.Prelude
                // will try to import frege.Prelude
                Left _ | name == prefix ++ "frege.Prelude" -> IO.return $ tree
                Left jex           -> IO.return $ Left (n, "Could not import package "
                                                        ++ name
                                                        ++ " (" ++ show jex ++ ")")
                Right (Just oparr) -> IO.return $ fold ins tree [ oparr.[i] | i <- 0..oparr.length - 1]
                _                  -> IO.return $ tree      // no operators
        where
            name = prefix ++ (fold (++) "" <~ map Token.value <~ takeWhile packToken) ts
            // loaded = getOperators loader name
            packToken :: Token -> Bool
            packToken t
                // t.tokid == VARID && t.value == "as" = false
                | t.tokid == VARID     = true
                | t.tokid == CONID     = true
                | t.tokid == QUALIFIER = true
                | t `is` '.' = true
                | otherwise = false
            ins (err@Left _)   _        = err
            // ins (tree@Right _) Nothing  = tree
            ins (Right tree)  op
                // later imported ops replace earlier ones
              /* | Just _ <- Tree.lookup tree key = Right tree
              | otherwise */ = Right result where
                result = Tree.insert tree key val
                !key = Operator.name op
                !xop | Operator.kind op == 0  = LOP0
                     | Operator.kind op == 1  = ROP0
                     | otherwise = NOP0
                !val = TokenID.from (TokenID.ord xop + Operator.prec op)


processInfix xs = fold single (Right specialT) xs where
    single (err@Left _) _ = err
    single (tree@Right _)  (t1:ts)
        | null ts = Left (Token.line t1, "Malformed «" ++ t1.value ++ "» declaration.")
        | Token.tokid t1 == INFIXL = mkInfix LOP0 ts tree
        | Token.tokid t1 == INFIXR = mkInfix ROP0 ts tree
        | Token.tokid t1 == INFIX  = mkInfix NOP0 ts tree
        | Token.tokid t1 == IMPORT = tree // mkImport t1.line ts tree
        | otherwise = Left (Token.line t1, "Token «" ++ t1.value ++ "» is invalid here")
    single _ [] = error ("single: empty command")
    mkInfix op [] tree = error "Cannot happen, this is checked in single"
    mkInfix op (t1:ts) tree
        | Token INTCONST s _ _ <- t1, i <- s.atoi, i > 0 && i < 17,
          opid <- TokenID.from (TokenID.ord op + i) = fold (mkOp opid) tree ts
        | otherwise = Left (t1.line, "Illegal precedence «" ++ t1.value ++ "», must be integer between 1..16")
    mkOp opid (err@Left _) token = err
    mkOp opid (Right tree) token
        | t `elem` [SOMEOP, VARID, CONID, CHAR], validop s = result
        | otherwise = Left (token.line, "Illegal operator «" ++ s ++ "»")
        where
            t = Token.tokid token
            s = Token.value token
            result = Right (Tree.insert tree s opid)



//* check if first token is followed without space by second
vor :: Token -> Token -> Bool
vor t1 t2 = t1.line == t2.line &&
            (t1.tokid == CHAR && t1.col + 1 == t2.col ||
             t1.tokid != CHAR && t1.col + length t1.value == t2.col)

data SM a b = SMT (Tree a (SM a b)) (Maybe b)
type SMCT = SM Char TokenID

statemachine :: SM Char TokenID -> [([Char], TokenID)] -> SM Char TokenID
statemachine sm [] = sm
statemachine (SMT tree Nothing) (([], t):bs) = statemachine (SMT tree (Just t)) bs
statemachine (SMT tree mb) ((c:cs, t):os)
    = statemachine (SMT (tree.insert c subsm) mb) other
    where
        startswith :: Char -> [Char] -> Bool
        startswith c (x:xs) = c == x
        startswith c [] = false
        (same, other) = partition (startswith c • fst) os
        subsm = statemachine (SMT Nil Nothing) ((cs, t):map (\(a,b) -> (tail a, b)) same)
statemachine (SMT tree (Just _)) (([], _):_) = error "This can only happen when keys are not unique."

interpret (SMT t r) [] = (r, [])
interpret (SMT t r) (ccs@c:cs) = case t.lookup c of
        Nothing -> (r, ccs)
        Just sm -> case interpret sm cs of
            (Nothing, _) -> (r, ccs)
            res          -> res

/**
 * build a statmachine for character sequences from a list of type [('String', 'TokenID')]
 */
buildSMCT = statemachine (SMT Nil Nothing) • map (\(as,b) -> (stocs as, b))

/**
 * Substitute char sequences with operators, 'SOMEOP' with operator,
 * QULIFIER OP with a single token by constructing a statemachine and
 * calling 'substOp' that does the real work.
 */
substAllOp :: Tree String TokenID -> [Token] -> [Token]
// construct the set of start characters of operators
substAllOp tree ts = substOp sm  tree ts where
    sm = (buildSMCT • Tree.each) tree
/**
 * Substitute char sequences with operators by recognizing the
 * longest sequence that forms an operator without backtracking,
 * 'SOMEOP' with operator,
 * 'QUALIFIER' OP with a single token.
 *
 * The first argument is a statemachine of type 'SMCT' that reognizes all known operators.
 *
 * The statemachine was introduced when I tried out what would happen if I passed a file with
 * wrong encoding or a binary file. In that case, long sequences of bytes are recognized
 * by 'scan' as @Token { tokid = CHAR, ... }@ and then in the earlier version of 'substOp'
 * the longest sequence of 'CHAR' tokens was collected, a string was build,
 * checked against the operator table
 * and when there was no match, the last 'CHAR' was pushed back and the processing repeated
 * until we had a match or a string of length 0 and only then was the first character
 * taken as 'CHAR' and substOp continued with the rest of the sequence.
 *
 * While this is no problem with 2 or 3 character seqences, the runtime explodes with every
 * additional character. To avoid this, I invented the statemachine that sees immediately
 * when a string has no initial sequence that builds a known operator.
 */
substOp :: SMCT -> Tree String TokenID -> [Token] -> [Token]
substOp start tree [] = []
substOp start tree (t:ts)
    | t.tokid == CHAR, forbidden (cval t)
                = t : substOp start tree ts
    | t.tokid == SOMEOP = case tree.lookup t.value of
                Just tid -> Token tid t.value t.line t.col   : substOp start tree ts
                Nothing  -> Token NOP1 t.value t.line t.col  : substOp start tree ts
    | t.tokid == QUALIFIER = case substOp start tree ts of
                (tx:ts) | t `vor` tx, tx.tokid > LOP0, tx.tokid < SOMEOP
                    = Token tx.tokid (t.value ++ tx.value) t.line t.col : ts
                ts  -> t:ts
    | t.tokid == CHAR
                = check (collect t ts) (t:ts)
    | otherwise = t: substOp start tree ts
    where
        collect :: Token -> [Token] -> [Char]
        collect t [] = [cval t]
        collect t (x:ts)
            | x.tokid == CHAR, !(forbidden (cval x)), t `vor` x = cval t:collect x ts
            | otherwise = [cval t]
        // check [] ts = (head ts) : substOp start tree  (tail ts)
        check cs ts = case interpret start cs of
            (Nothing, _) -> head ts : substOp start tree (tail ts)
            (Just op, rest) ->
                Token op (name rest) (Token.line (head ts)) (Token.col (head ts))
                : substOp start tree (drop (length cs - length rest) ts)
            // otherwise = check tree (init xs) ts
          where name rest = cstos (take (length cs - length rest) cs)

//* this is the lexical analysis pass
pass :: (String -> IO (Exception (Maybe OpArr))) -> StG [Token]
pass getop =
    do
        global <- getST
        let opts   = global.options
            // loader = global.classLoader
            prefix = opts.prefix
        ebr <- doio (openSrc opts.encoding opts.source)
        case ebr of
            Left exc -> do
                U.error 0 ("Cannot open source file: " ++ show exc)
                // g <- getST
                // changeST Global.{errors <- (+1)}
                stio []     // IO.return ([], global.{errors <- (+1)})
            Right br -> do
                // doio $ stderr << '.'
                lines <- doio $ br.getlines
                // doio $ stderr << '.'
                let tokens  =  (layout [0] <~ scan 1) lines
                    ifximps = (reverse <~ findInfixImports) tokens
                    tree0   = processInfix ifximps
                imps <- doio $ processImports prefix getop (Right specialT) ifximps
                let tree2 = either Left (ourinfix tree0) imps
                    // enter infix defined symbols last
                    ourinfix (Right t0)    t = ourins t (each t0)
                    ourinfix (left@Left _) _ = left
                    ourins t [] = Right t
                    ourins t ((k,v):kvs) = ourins (Tree.insert t k v) kvs
                either (failure) (success tokens) tree2
    where
        failure (n, s) = do
            // doio $ stderr << '\n'
            U.error n s
            stio []
        success :: [Token] -> Tree String TokenID -> StG [Token]
        success tokens tree = do
            // doio $ stderr << '.'
            changeST Global.{sub <- SubSt.{optab = tree}}
            stio (substAllOp tree tokens)

        openSrc Nothing "-"  = do input <- stdin
                                  isr <- InputStreamReader.new input
                                  brFromISR (Right isr)
        openSrc Nothing s = BufferedReader.open s
        openSrc (Just enc) "-" = do
                                    input <- stdin
                                    brFromIS enc input
        openSrc (Just enc) s = do
            fis <- FileInputStream.open s
            case fis of
                Left err -> IO.return (Left err)
                Right fis -> brFromIS enc fis.inputStream

        brFromIS enc is = do
                    isr <- InputStreamReader.encoded is enc
                    brFromISR isr

        brFromISR eisr = case eisr of
                        Left  err -> IO.return (Left err)
                        Right isr -> do
                            br <- BufferedReader.fromISR isr
                            IO.return (Right br)
